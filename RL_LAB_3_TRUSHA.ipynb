{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "999bcd7d",
      "metadata": {
        "id": "999bcd7d"
      },
      "source": [
        "# Lab 3: Contextual Bandit-Based News Article Recommendation\n",
        "\n",
        "**`Course`:** Reinforcement Learning Fundamentals  \n",
        "**`Student Name`:**  \n",
        "**`Roll Number`:**  \n",
        "**`GitHub Branch`:** firstname_U20230xxx  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "755efd7a",
      "metadata": {
        "id": "755efd7a"
      },
      "source": [
        "# Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ef4bd959",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "ef4bd959",
        "outputId": "a4b7de9c-1b6c-4fde-b6d2-5b462046e544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rlcmab-sampler\n",
            "  Downloading rlcmab_sampler-1.0.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting numpy>=2.4.2 (from rlcmab-sampler)\n",
            "  Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting scipy>=1.17.0 (from rlcmab-sampler)\n",
            "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rlcmab_sampler-1.0.1-py3-none-any.whl (2.8 kB)\n",
            "Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, rlcmab-sampler\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.4.2 rlcmab-sampler-1.0.1 scipy-1.17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "551fdd8284734c079cac1692d09cb936"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install rlcmab-sampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple, List, Optional\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "FCZ0cTwXSQbo"
      },
      "id": "FCZ0cTwXSQbo",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from rlcmab_sampler import sampler\n"
      ],
      "metadata": {
        "id": "kIyXTdooK007"
      },
      "id": "kIyXTdooK007",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c638ba06",
      "metadata": {
        "id": "c638ba06"
      },
      "source": [
        "# Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "48f6f6a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48f6f6a6",
        "outputId": "c287a84c-72d9-4fc1-dd22-c594f3423ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                link  \\\n",
            "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
            "1  https://www.huffpost.com/entry/american-airlin...   \n",
            "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
            "3  https://www.huffpost.com/entry/funniest-parent...   \n",
            "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
            "\n",
            "                                            headline   category  \\\n",
            "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
            "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
            "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
            "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
            "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
            "\n",
            "                                   short_description               authors  \\\n",
            "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
            "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
            "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
            "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
            "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
            "\n",
            "         date  \n",
            "0  2022-09-23  \n",
            "1  2022-09-23  \n",
            "2  2022-09-23  \n",
            "3  2022-09-23  \n",
            "4  2022-09-22  \n",
            "   user_id  age  income  clicks  purchase_amount  label\n",
            "0        1   28   58242      81           378.38  user3\n",
            "1        2   28   38225      21           114.50  user3\n",
            "2        3   39   95017      41            66.24  user2\n",
            "3        4   52   33473      98           496.88  user3\n",
            "4        5   29   80690       5           293.24  user1\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "news_df = pd.read_csv(\"news_articles.csv\")\n",
        "train_users = pd.read_csv(\"train_users.csv\")\n",
        "test_users = pd.read_csv(\"test_users.csv\")\n",
        "\n",
        "print(news_df.head())\n",
        "print(train_users.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a1c5cb1",
      "metadata": {
        "id": "5a1c5cb1"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "In this section:\n",
        "- Handle missing values\n",
        "- Encode categorical features\n",
        "- Prepare data for user classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROLL_NUMBER = 139\n",
        "\n",
        "PATH_TRAIN_USERS = \"train_users.csv\"\n",
        "PATH_TEST_USERS  = \"test_users.csv\"\n",
        "PATH_ARTICLES    = \"news_articles.csv\"\n",
        "\n",
        "T = 10_000\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "FpJodaq3R_Mh"
      },
      "id": "FpJodaq3R_Mh",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_CONTEXTS = [\"User1\", \"User2\", \"User3\"]\n",
        "NEWS_CATEGORIES = [\"Entertainment\", \"Education\", \"Tech\", \"Crime\"]\n",
        "\n",
        "CATEGORY_TO_IDX = {c: i for i, c in enumerate(NEWS_CATEGORIES)}\n",
        "IDX_TO_CATEGORY = {i: c for c, i in CATEGORY_TO_IDX.items()}\n",
        "\n",
        "CONTEXT_TO_IDX = {u: i for i, u in enumerate(USER_CONTEXTS)}\n",
        "IDX_TO_CONTEXT = {i: u for u, i in CONTEXT_TO_IDX.items()}\n",
        "\n",
        "def arm_index(context: str, category: str) -> int:\n",
        "    \"\"\"\n",
        "    Maps (context, category) -> j in [0..11] according to PDF table:\n",
        "    User1: 0..3, User2: 4..7, User3: 8..11\n",
        "    in order: Entertainment, Education, Tech, Crime\n",
        "    \"\"\"\n",
        "    ci = CONTEXT_TO_IDX[context]          # 0,1,2\n",
        "    ai = CATEGORY_TO_IDX[category]        # 0..3\n",
        "    return ci * 4 + ai"
      ],
      "metadata": {
        "id": "ImfAKlSJShIq"
      },
      "id": "ImfAKlSJShIq",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv_or_raise(path: str) -> pd.DataFrame:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Could not find file: {path}\")\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "train_users = load_csv_or_raise(PATH_TRAIN_USERS)\n",
        "test_users  = load_csv_or_raise(PATH_TEST_USERS)\n",
        "articles    = load_csv_or_raise(PATH_ARTICLES)\n",
        "\n",
        "POSSIBLE_USER_LABEL_COLS = [\"classifying\", \"class\", \"label\", \"user_class\", \"user_type\"]\n",
        "user_label_col = next((c for c in POSSIBLE_USER_LABEL_COLS if c in train_users.columns), None)\n",
        "if user_label_col is None:\n",
        "    raise ValueError(\n",
        "        f\"Could not find user label column. Tried: {POSSIBLE_USER_LABEL_COLS}. \"\n",
        "        f\"Columns found: {list(train_users.columns)}\"\n",
        "    )\n",
        "\n",
        "if \"category\" not in articles.columns:\n",
        "    raise ValueError(f\"news_articles.csv must have a 'category' column. Columns: {list(articles.columns)}\")"
      ],
      "metadata": {
        "id": "R5Z9buVDSk__"
      },
      "id": "R5Z9buVDSk__",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CENTWpruWIvz"
      },
      "id": "CENTWpruWIvz",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def build_user_classifier(train_df: pd.DataFrame, label_col: str) -> Tuple[Pipeline, List[str]]:\n",
        "    X = train_df.drop(columns=[label_col])\n",
        "    y = train_df[label_col].astype(str)\n",
        "\n",
        "    numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
        "    categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
        "\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_transformer, numeric_cols),\n",
        "            (\"cat\", categorical_transformer, categorical_cols)\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "\n",
        "    # Decision Tree Classifier (stronger than plain logistic regression on many tabular sets)\n",
        "    clf = DecisionTreeClassifier(\n",
        "        max_depth=None,          # you can tune: 5, 8, 12, None\n",
        "        min_samples_split=12,    # you can tune: 2, 5, 10\n",
        "        min_samples_leaf=2,      # you can tune: 1, 2, 5\n",
        "        class_weight=\"balanced\", # helps if User1/User2/User3 are imbalanced\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model = Pipeline(steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"clf\", clf)\n",
        "    ])\n",
        "\n",
        "    return model, X.columns.tolist()\n",
        "\n",
        "\n",
        "# Train classifier\n",
        "user_model, user_feature_cols = build_user_classifier(train_users, user_label_col)\n",
        "X_train = train_users.drop(columns=[user_label_col])\n",
        "y_train = train_users[user_label_col].astype(str)\n",
        "user_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test_users\n",
        "if user_label_col in test_users.columns:\n",
        "    X_test = test_users.drop(columns=[user_label_col])\n",
        "    y_test = test_users[user_label_col].astype(str)\n",
        "    y_pred = user_model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(\"=== User Classifier Evaluation (Decision Tree) ===\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "else:\n",
        "    print(\"NOTE: test_users.csv has no label column; classifier accuracy cannot be computed.\")\n",
        "    X_test = test_users.copy()\n",
        "    y_pred = user_model.predict(X_test)\n",
        "    print(\"Predictions generated for test_users (first 10):\", y_pred[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZo4gfFGS6UN",
        "outputId": "6e614005-a614-480f-c1f3-a76e54ede602"
      },
      "id": "ZZo4gfFGS6UN",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== User Classifier Evaluation (Decision Tree) ===\n",
            "Accuracy: 0.334\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       User1       0.33      0.33      0.33       672\n",
            "       User2       0.37      0.35      0.36       679\n",
            "       User3       0.31      0.32      0.31       649\n",
            "\n",
            "    accuracy                           0.33      2000\n",
            "   macro avg       0.33      0.33      0.33      2000\n",
            "weighted avg       0.33      0.33      0.33      2000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[224 216 232]\n",
            " [220 238 221]\n",
            " [245 198 206]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XbEmiEP0UcGB"
      },
      "id": "XbEmiEP0UcGB",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2e4d6352",
      "metadata": {
        "id": "2e4d6352"
      },
      "source": [
        "## User Classification\n",
        "\n",
        "Train a classifier to predict the user category (`User1`, `User2`, `User3`),\n",
        "which serves as the **context** for the contextual bandit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3ba537f",
      "metadata": {
        "id": "b3ba537f"
      },
      "source": [
        "# `Contextual Bandit`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "465388d6",
      "metadata": {
        "id": "465388d6"
      },
      "source": [
        "## Reward Sampler Initialization\n",
        "\n",
        "The sampler is initialized using the student's roll number `i`.\n",
        "Rewards are obtained using `sampler.sample(j)`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8f0bb0f",
      "metadata": {
        "id": "f8f0bb0f"
      },
      "source": [
        "## Arm Mapping\n",
        "\n",
        "| Arm Index (j) | News Category | User Context |\n",
        "|--------------|---------------|--------------|\n",
        "| 0–3          | Entertainment, Education, Tech, Crime | User1 |\n",
        "| 4–7          | Entertainment, Education, Tech, Crime | User2 |\n",
        "| 8–11         | Entertainment, Education, Tech, Crime | User3 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "356c764d",
      "metadata": {
        "id": "356c764d"
      },
      "source": [
        "## Epsilon-Greedy Strategy\n",
        "\n",
        "This section implements the epsilon-greedy contextual bandit algorithm.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b571e8a6",
      "metadata": {
        "id": "b571e8a6"
      },
      "source": [
        "## Upper Confidence Bound (UCB)\n",
        "\n",
        "This section implements the UCB strategy for contextual bandits."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ff2fb86",
      "metadata": {
        "id": "1ff2fb86"
      },
      "source": [
        "## SoftMax Strategy\n",
        "\n",
        "This section implements the SoftMax strategy with temperature $ \\tau = 1$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb144662",
      "metadata": {
        "id": "fb144662"
      },
      "source": [
        "## Reinforcement Learning Simulation\n",
        "\n",
        "We simulate the bandit algorithms for $T = 10,000$ steps and record rewards.\n",
        "\n",
        "P.S.: Change $T$ value as and if required.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca10b073",
      "metadata": {
        "id": "ca10b073"
      },
      "source": [
        "## Results and Analysis\n",
        "\n",
        "This section presents:\n",
        "- Average Reward vs Time\n",
        "- Hyperparameter comparisons\n",
        "- Observations and discussion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "512fbb89",
      "metadata": {
        "id": "512fbb89"
      },
      "source": [
        "## Final Observations\n",
        "\n",
        "- Comparison of Epsilon-Greedy, UCB, and SoftMax\n",
        "- Effect of hyperparameters\n",
        "- Strengths and limitations of each approach\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5665d58e",
      "metadata": {
        "id": "5665d58e"
      },
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}